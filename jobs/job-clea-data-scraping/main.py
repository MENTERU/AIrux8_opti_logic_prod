from datetime import datetime

import pytz
from fastapi import FastAPI
from fastapi.responses import JSONResponse

from service.airux8_scraper import Alrux8Scraper
from service.secretmanager import SecretManagerClient

app = FastAPI()

# Track if scraping is currently running to prevent concurrent runs
scraping_in_progress = False


@app.get("/health")
async def health_check():
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    global scraping_in_progress
    return JSONResponse(
        {
            "status": "healthy",
            "scraping_in_progress": scraping_in_progress,
            "message": "ã‚µãƒ¼ãƒãƒ¼ã¯ç¨¼åƒä¸­ã§ã™",
        },
        status_code=200,
    )


@app.post("/run_scraping")
async def run_scraping():
    """ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Ÿè¡Œã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    global scraping_in_progress

    # Prevent concurrent scraping runs
    if scraping_in_progress:
        print(
            "âš ï¸ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã¯æ—¢ã«å®Ÿè¡Œä¸­ã§ã™ã€‚å‰ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒå®Œäº†ã™ã‚‹ã¾ã§å¾…æ©Ÿã—ã¦ãã ã•ã„ã€‚"
        )
        return JSONResponse(
            {"message": "ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã¯æ—¢ã«å®Ÿè¡Œä¸­ã§ã™", "status": "busy"},
            status_code=409,  # Conflict
        )

    scraper = None
    try:
        scraping_in_progress = True
        print("=" * 60)
        print("ğŸ“¥ æ–°ã—ã„ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å—ä¿¡ã—ã¾ã—ãŸ")
        print("=" * 60)

        # ãƒ­ã‚°ã‚¤ãƒ³æƒ…å ±ã‚’Secret Managerã‹ã‚‰å–å¾—
        secret_manager = SecretManagerClient()
        login_info = secret_manager.get_secret_as_dict("AIRUX8_WEB_LOGIN_INFO")

        if not login_info:
            scraping_in_progress = False
            return JSONResponse(
                {
                    "message": "Failed to retrieve login information from Secret Manager",
                    "status": "error",
                },
                status_code=500,
            )

        username = login_info.get("username")
        password = login_info.get("password")

        if not username or not password:
            scraping_in_progress = False
            return JSONResponse(
                {
                    "message": "Login information is missing username or password",
                    "status": "error",
                },
                status_code=500,
            )

        print("âœ… Successfully retrieved login information from Secret Manager")

        # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ä½œæˆ
        scraper = Alrux8Scraper()
        store_name = "Clea"
        start_date = datetime(2025, 11, 12, tzinfo=pytz.timezone("Asia/Tokyo"))
        end_date = datetime(2025, 11, 12, tzinfo=pytz.timezone("Asia/Tokyo"))
        data_types = ["A/C Power Meter", "A/Cåˆ¶å¾¡"]

        print(f"=== {store_name} ãƒ‡ãƒ¼ã‚¿å–å¾—é–‹å§‹ ===")
        print(
            f"æœŸé–“: {start_date.strftime('%Y-%m-%d')} ï½ {end_date.strftime('%Y-%m-%d')}"
        )
        print(f"ãƒ‡ãƒ¼ã‚¿: {', '.join(data_types)}")

        # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Ÿè¡Œ
        success = await scraper.run_scraping(
            username=username,
            password=password,
            store_name=store_name,
            start_date=start_date,
            end_date=end_date,
            data_types=data_types,
        )

        if success:
            print("=" * 60)
            print("âœ… ãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº† - ã‚µãƒ¼ãƒãƒ¼ã¯å¾…æ©Ÿä¸­ã§ã™")
            print("=" * 60)
            scraping_in_progress = False
            return JSONResponse(
                {
                    "message": "ãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº†",
                    "status": "success",
                    "store": store_name,
                    "date_range": f"{start_date.strftime('%Y-%m-%d')} ï½ {end_date.strftime('%Y-%m-%d')}",
                },
                status_code=200,
            )
        else:
            print("=" * 60)
            print("âŒ ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•— - ã‚µãƒ¼ãƒãƒ¼ã¯å¾…æ©Ÿä¸­ã§ã™")
            print("=" * 60)
            scraping_in_progress = False
            return JSONResponse(
                {
                    "message": "ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—",
                    "status": "failed",
                    "store": store_name,
                },
                status_code=200,  # Return 200 even on failure, but status indicates failure
            )
    except Exception as error:
        print("=" * 60)
        print(f"âŒ ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {error}")
        print("=" * 60)
        scraping_in_progress = False
        return JSONResponse(
            {
                "message": f"ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {str(error)}",
                "status": "error",
            },
            status_code=500,
        )
    finally:
        scraping_in_progress = False
        if scraper is not None:
            await scraper.close()
        print("ğŸ”„ ã‚µãƒ¼ãƒãƒ¼ã¯æ¬¡ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å¾…æ©Ÿä¸­...")


if __name__ == "__main__":
    import uvicorn

    uvicorn.run(app, host="0.0.0.0", port=8080)
