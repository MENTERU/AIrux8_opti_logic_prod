#!/usr/bin/env python3
"""
Alrux8ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ï¼ˆPlaywrightç‰ˆï¼‰
æœ¬ç•ªç”¨ã®æ•´ç†ã•ã‚ŒãŸãƒãƒ¼ã‚¸ãƒ§ãƒ³
"""

import asyncio
import logging
import os
import shutil
from datetime import datetime
from pathlib import Path

import pandas as pd
from config.config_gcp import GCPEnv
from playwright.async_api import async_playwright
from service.bigquery import BigQuery
from service.storage import GCSClient

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[
        logging.StreamHandler(),
    ],
)
logger = logging.getLogger(__name__)


class Alrux8Scraper:
    def __init__(
        self,
        bq_dataset_id: str,
        bq_table_ac_control_raw: str,
        bq_table_ac_power_meter_raw: str,
    ):
        self.browser = None
        self.page = None
        self.context = None
        self.playwright = None
        self.download_summary = {}  # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰çµæœã®è¦ç´„
        self.downloaded_files = []  # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã¨ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—ã®ãƒãƒƒãƒ”ãƒ³ã‚°

        # Data type name mapping (Japanese to English)
        # The website displays buttons in English, not Japanese
        self.data_type_mapping = {
            "A/Cåˆ¶å¾¡": "A/C Control",
            "A/C Power Meter": "A/C Power Meter",  # Already in English
        }

        # Get the base directory (job-clea-data-scraping directory)
        # This file is in service/, so we go up one level to get the job root
        script_dir = Path(__file__).parent.parent
        self.base_dir = script_dir.resolve()

        # Initialize GCS client with service account credentials if available
        service_account_path = GCPEnv.SERVICE_ACCOUNT_JSON
        if os.path.exists(service_account_path):
            logger.info(f"GCSèªè¨¼æƒ…å ±ã‚’ä½¿ç”¨: {service_account_path}")
        else:
            logger.info("Application Default Credentialsã‚’ä½¿ç”¨")
        self.gcs_client = GCSClient(
            project_id=GCPEnv.PROJECT_ID,
            bucket_id=GCPEnv.BUCKET_NAME,
            credentials_path=(
                service_account_path if os.path.exists(service_account_path) else None
            ),
        )
        # Initialize BigQuery client for ingesting scraped data
        self.bq_client = BigQuery(project_id=GCPEnv.PROJECT_ID)
        self.bq_dataset_id = bq_dataset_id
        self.bq_table_ac_control_raw = bq_table_ac_control_raw
        self.bq_table_ac_power_meter_raw = bq_table_ac_power_meter_raw
        # Create necessary directories
        self._create_directories()

    def _create_directories(self):
        """å¿…è¦ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ"""
        logs_dir = self.base_dir / "logs"
        downloads_dir = self.base_dir / "downloads"
        alrux8_data_dir = self.base_dir / "alrux8_data"

        os.makedirs(str(logs_dir), exist_ok=True)
        os.makedirs(str(downloads_dir), exist_ok=True)
        os.makedirs(str(alrux8_data_dir), exist_ok=True)
        logger.info(f"å¿…è¦ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆã—ã¾ã—ãŸ: {self.base_dir}")

    async def setup_browser(self):
        """ãƒ–ãƒ©ã‚¦ã‚¶ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        try:
            logger.info("ãƒ–ãƒ©ã‚¦ã‚¶ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—é–‹å§‹")

            self.playwright = await async_playwright().start()
            self.browser = await self.playwright.chromium.launch(
                headless=True,  # Required for Docker/Cloud Run (no display server)
                args=[
                    "--no-sandbox",
                    "--disable-dev-shm-usage",
                    "--disable-gpu",
                    "--ignore-certificate-errors",
                    "--disable-extensions",
                    "--disable-plugins",
                ],
            )

            self.context = await self.browser.new_context(
                accept_downloads=True,
                viewport={
                    "width": 1920,
                    "height": 1080,
                },  # Set viewport for headless mode
            )
            self.page = await self.context.new_page()

            logger.info("ãƒ–ãƒ©ã‚¦ã‚¶ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†")
            return True

        except Exception as e:
            logger.error(f"ãƒ–ãƒ©ã‚¦ã‚¶ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    async def login(self, username, password):
        """ãƒ­ã‚°ã‚¤ãƒ³å‡¦ç†"""
        try:
            logger.info(f"ãƒ­ã‚°ã‚¤ãƒ³é–‹å§‹: {username}")

            await self.page.goto("https://www.airux8.com/login")
            await self.page.wait_for_load_state("networkidle")

            await self.page.fill("input[name='username']", username)
            await self.page.fill("input[name='password']", password)
            await self.page.wait_for_timeout(1000)

            await self.page.click("button[type='submit']")
            await self.page.wait_for_timeout(5000)

            current_url = self.page.url
            logger.info(f"ãƒ­ã‚°ã‚¤ãƒ³å¾Œã®URL: {current_url}")

            if "login" not in current_url.lower():
                logger.info("ãƒ­ã‚°ã‚¤ãƒ³æˆåŠŸ")
                return True
            else:
                logger.error("ãƒ­ã‚°ã‚¤ãƒ³å¤±æ•—")
                return False

        except Exception as e:
            logger.error(f"ãƒ­ã‚°ã‚¤ãƒ³ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    async def navigate_to_logs(self):
        """Logsãƒšãƒ¼ã‚¸ã«ç§»å‹•"""
        try:
            logger.info("Logsãƒšãƒ¼ã‚¸ã«ç§»å‹•")
            await self.page.goto("https://www.airux8.com/airux-admin/logs")
            await self.page.wait_for_load_state("networkidle")
            return True
        except Exception as e:
            logger.error(f"Logsãƒšãƒ¼ã‚¸ç§»å‹•ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    async def select_date_range(self, start_date, end_date):
        """æ—¥ä»˜ç¯„å›²é¸æŠï¼ˆé–‹å§‹æœˆã¨çµ‚äº†æœˆãŒç•°ãªã‚‹å ´åˆã‚‚å¯¾å¿œï¼‰"""
        try:
            logger.info(
                f"æ—¥ä»˜ç¯„å›²é¸æŠ: {start_date.strftime('%Y-%m-%d')} ï½ {end_date.strftime('%Y-%m-%d')}"
            )

            # æ—¥ä»˜ãƒ”ãƒƒã‚«ãƒ¼ãŒè¡¨ç¤ºã•ã‚Œã‚‹ã¾ã§å¾…æ©Ÿ
            logger.info("æ—¥ä»˜ãƒ”ãƒƒã‚«ãƒ¼è¦ç´ ã®è¡¨ç¤ºã‚’å¾…æ©Ÿä¸­...")
            await self.page.wait_for_selector("select", state="visible", timeout=30000)
            await self.page.wait_for_timeout(1000)  # è¿½åŠ ã®å®‰å®šåŒ–å¾…æ©Ÿ

            # å¹´ãƒ»æœˆã®é¸æŠï¼ˆé–‹å§‹æ—¥ï¼‰
            year_selector = self.page.locator("select").nth(1)
            await year_selector.wait_for(state="visible", timeout=30000)
            await year_selector.select_option(str(start_date.year))
            await self.page.wait_for_timeout(500)

            month_selector = self.page.locator("select").nth(0)
            await month_selector.wait_for(state="visible", timeout=30000)
            await month_selector.select_option(str(start_date.month - 1))
            await self.page.wait_for_timeout(1000)

            # é–‹å§‹æ—¥ã‚¯ãƒªãƒƒã‚¯
            logger.info("é–‹å§‹æ—¥ãƒœã‚¿ãƒ³ã®è¡¨ç¤ºã‚’å¾…æ©Ÿä¸­...")
            await self.page.wait_for_selector(
                "button.rdrDay:not(.rdrDayPassive):not(.rdrDayDisabled)",
                state="visible",
                timeout=30000,
            )
            start_day = (
                self.page.locator(
                    "button.rdrDay:not(.rdrDayPassive):not(.rdrDayDisabled)"
                )
                .filter(has_text=str(start_date.day))
                .first
            )
            await start_day.wait_for(state="visible", timeout=30000)
            await start_day.scroll_into_view_if_needed()
            await start_day.click()
            await self.page.wait_for_timeout(500)

            # çµ‚äº†æ—¥ãŒé–‹å§‹æœˆã¨ç•°ãªã‚‹å ´åˆã€ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã‚’åˆ‡ã‚Šæ›¿ãˆ
            if start_date.year != end_date.year or start_date.month != end_date.month:
                await year_selector.select_option(str(end_date.year))
                await self.page.wait_for_timeout(500)
                await month_selector.select_option(str(end_date.month - 1))
                await self.page.wait_for_timeout(1000)

            # çµ‚äº†æ—¥ã‚¯ãƒªãƒƒã‚¯
            logger.info("çµ‚äº†æ—¥ãƒœã‚¿ãƒ³ã®è¡¨ç¤ºã‚’å¾…æ©Ÿä¸­...")
            end_day = (
                self.page.locator(
                    "button.rdrDay:not(.rdrDayPassive):not(.rdrDayDisabled)"
                )
                .filter(has_text=str(end_date.day))
                .first
            )
            await end_day.wait_for(state="visible", timeout=30000)
            await end_day.scroll_into_view_if_needed()
            await end_day.click()
            await self.page.wait_for_timeout(500)

            logger.info("æ—¥ä»˜ç¯„å›²é¸æŠå®Œäº†")
            return True

        except Exception as e:
            logger.error(f"æ—¥ä»˜ç¯„å›²é¸æŠã‚¨ãƒ©ãƒ¼: {e}")
            return False

    async def get_available_floors(self):
        """åˆ©ç”¨å¯èƒ½ãªãƒ•ãƒ­ã‚¢ä¸€è¦§ã‚’å–å¾—"""
        try:
            logger.info("ãƒ•ãƒ­ã‚¢ä¸€è¦§å–å¾—é–‹å§‹")

            # Wait for the combobox input to be visible
            # Try to find the input - it might have "æ¤œç´¢ä¸­..." placeholder while loading
            # or a different placeholder when ready
            logger.info("ãƒ•ãƒ­ã‚¢ã‚³ãƒ³ãƒœãƒœãƒƒã‚¯ã‚¹ã‚’æ¢ã—ã¦ã„ã¾ã™...")

            # First, try to find any input that looks like a combobox/search input
            # Wait for the page to be ready after date selection
            await self.page.wait_for_timeout(2000)

            # Try multiple selectors - the placeholder might change after loading
            floor_combobox = None
            selectors = [
                "input[placeholder*='æ¤œç´¢']",  # Any input with "æ¤œç´¢" in placeholder
                "input[placeholder='æ¤œç´¢ä¸­...']",  # Loading state
                "input[type='text']",  # Generic text input (fallback)
            ]

            for selector in selectors:
                try:
                    test_locator = self.page.locator(selector).first
                    await test_locator.wait_for(state="visible", timeout=10000)
                    floor_combobox = test_locator
                    logger.info(f"ãƒ•ãƒ­ã‚¢ã‚³ãƒ³ãƒœãƒœãƒƒã‚¯ã‚¹ã‚’è¦‹ã¤ã‘ã¾ã—ãŸ: {selector}")
                    break
                except Exception as e:
                    logger.debug(f"ã‚»ãƒ¬ã‚¯ã‚¿ãƒ¼ {selector} ã§è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ: {e}")
                    continue

            if floor_combobox is None:
                raise Exception("ãƒ•ãƒ­ã‚¢ã‚³ãƒ³ãƒœãƒœãƒƒã‚¯ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")

            # Wait for element to be enabled and ready
            await self.page.wait_for_timeout(2000)
            is_enabled = await floor_combobox.is_enabled()
            if not is_enabled:
                logger.warning("ãƒ•ãƒ­ã‚¢ã‚³ãƒ³ãƒœãƒœãƒƒã‚¯ã‚¹ãŒæœ‰åŠ¹ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚å¾…æ©Ÿä¸­...")
                await self.page.wait_for_timeout(5000)

            # Scroll into view and click
            await floor_combobox.scroll_into_view_if_needed()
            await floor_combobox.click(timeout=30000)
            await self.page.wait_for_timeout(1000)

            floor_options = self.page.locator("li[role='option']")
            option_count = await floor_options.count()

            floors = []
            for i in range(option_count):
                text = await floor_options.nth(i).text_content()
                if text and text.strip():
                    floors.append(text.strip())

            logger.info(f"ãƒ•ãƒ­ã‚¢ä¸€è¦§: {floors}")
            return floors

        except Exception as e:
            logger.error(f"ãƒ•ãƒ­ã‚¢ä¸€è¦§å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return []

    async def select_floor(self, floor_name):
        """ãƒ•ãƒ­ã‚¢é¸æŠ"""
        try:
            logger.info(f"ãƒ•ãƒ­ã‚¢é¸æŠ: {floor_name}")

            floor_option = (
                self.page.locator("li[role='option']").filter(has_text=floor_name).first
            )
            await floor_option.click()
            await self.page.wait_for_timeout(1000)

            return True

        except Exception as e:
            logger.error(f"ãƒ•ãƒ­ã‚¢é¸æŠã‚¨ãƒ©ãƒ¼: {e}")
            return False

    async def get_floor_ac_master(self):
        """ãƒ•ãƒ­ã‚¢ã”ã¨ã®A/Cæ©Ÿå™¨ãƒªã‚¹ãƒˆã‚’ãƒã‚¹ã‚¿ã¨ã—ã¦å–å¾—"""
        logger.info("ãƒ•ãƒ­ã‚¢ãƒ»A/Cãƒã‚¹ã‚¿æƒ…å ±å–å¾—é–‹å§‹")
        master = {}
        floors = await self.get_available_floors()
        for floor in floors:
            # ãƒ•ãƒ­ã‚¢é¸æŠ
            await self.select_floor(floor)
            await self.page.wait_for_timeout(1000)
            # A/Cæ©Ÿå™¨ãƒªã‚¹ãƒˆå–å¾—
            ac_combobox = self.page.locator("input[aria-multiselectable='true']").first
            await ac_combobox.click()
            await self.page.wait_for_timeout(1000)
            ac_options = self.page.locator("li[role='option']")
            ac_count = await ac_options.count()
            ac_list = []
            for i in range(ac_count):
                ac_text = await ac_options.nth(i).text_content()
                if ac_text and ac_text.strip():
                    ac_list.append(ac_text.strip())
            # ãƒ•ãƒ­ã‚¢åã¨ä¸€è‡´ã™ã‚‹ã‚‚ã®ã¯é™¤å¤–
            ac_list = [ac for ac in ac_list if ac not in floors]
            master[floor] = ac_list
            # A/Cé¸æŠè§£é™¤ï¼ˆæ¬¡ã®ãƒ•ãƒ­ã‚¢ã®ãŸã‚ï¼‰
            await ac_combobox.press("Escape")
            await self.page.wait_for_timeout(500)
        logger.info(f"ãƒã‚¹ã‚¿æƒ…å ±: {master}")
        self.floor_ac_master = master
        return master

    async def select_ac_units_by_names(self, ac_names):
        """A/Cæ©Ÿå™¨åãƒªã‚¹ãƒˆã§é¸æŠ"""
        try:
            logger.info(f"A/Cæ©Ÿå™¨é¸æŠ: {ac_names}")
            ac_combobox = self.page.locator("input[aria-multiselectable='true']").first
            await ac_combobox.click()
            await self.page.wait_for_timeout(1000)
            ac_options = self.page.locator("li[role='option']")
            selected = 0
            for name in ac_names:
                option = ac_options.filter(has_text=name).first
                await option.click()
                await self.page.wait_for_timeout(500)
                selected += 1
            logger.info(f"A/Cæ©Ÿå™¨é¸æŠå®Œäº†: {selected}/{len(ac_names)}å°")
            return selected
        except Exception as e:
            logger.error(f"A/Cæ©Ÿå™¨åæŒ‡å®šé¸æŠã‚¨ãƒ©ãƒ¼: {e}")
            return 0

    async def select_all_ac_units(self):
        """å…¨A/Cæ©Ÿå™¨é¸æŠï¼ˆå®‰å®šç‰ˆï¼‰"""
        try:
            logger.info("å…¨A/Cæ©Ÿå™¨é¸æŠé–‹å§‹")

            ac_combobox = self.page.locator("input[aria-multiselectable='true']").first
            await ac_combobox.click()
            await self.page.wait_for_timeout(1000)

            ac_options = self.page.locator("li[role='option']")
            option_count = await ac_options.count()
            logger.info(f"A/Cã‚ªãƒ—ã‚·ãƒ§ãƒ³æ•°: {option_count}")

            # æœ€åˆã®5å°ã®ã¿é¸æŠï¼ˆå®‰å®šæ€§é‡è¦–ï¼‰
            max_selections = min(5, option_count)
            selected_count = 0

            for i in range(max_selections):
                try:
                    option = ac_options.nth(i)
                    await option.click()
                    await self.page.wait_for_timeout(500)  # å‡¦ç†é–“éš”ã‚’å»¶é•·
                    selected_count += 1
                    logger.info(f"A/Cæ©Ÿå™¨ {i} é¸æŠå®Œäº†")
                except Exception as e:
                    logger.warning(f"A/Cæ©Ÿå™¨ {i} é¸æŠå¤±æ•—: {e}")
                    # å¤±æ•—ã—ã¦ã‚‚ç¶šè¡Œ
                    continue

            logger.info(f"A/Cæ©Ÿå™¨é¸æŠå®Œäº†: {selected_count}/{max_selections}å°")
            return selected_count

        except Exception as e:
            logger.error(f"A/Cæ©Ÿå™¨é¸æŠã‚¨ãƒ©ãƒ¼: {e}")
            return 0

    async def download_data_type(self, data_type):
        """ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰æœ€é©åŒ–ç‰ˆï¼‰"""
        max_retries = 3
        retry_delay = 5000  # 5 seconds between retries

        # Translate data type name if needed (Japanese to English)
        display_name = self.data_type_mapping.get(data_type, data_type)
        if display_name != data_type:
            logger.info(
                f"ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—åå¤‰æ›: '{data_type}' â†’ '{display_name}' (ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆè¡¨ç¤ºå)"
            )

        for attempt in range(max_retries):
            try:
                if attempt > 0:
                    logger.info(f"ãƒªãƒˆãƒ©ã‚¤ {attempt + 1}/{max_retries}: {data_type}")
                    await self.page.wait_for_timeout(retry_delay)

                logger.info(
                    f"ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é–‹å§‹: {data_type} (è¡¨ç¤ºå: {display_name})"
                )

                # Wait for page to be stable after previous operations
                await self.page.wait_for_load_state("domcontentloaded", timeout=30000)
                await self.page.wait_for_timeout(3000)

                # Check for and dismiss any modal/overlay that might be blocking the page
                try:
                    # Common modal close button selectors
                    modal_close_selectors = [
                        "button[aria-label='Close']",
                        "button.close",
                        ".modal-close",
                        "[data-dismiss='modal']",
                        ".overlay-close",
                    ]
                    for close_selector in modal_close_selectors:
                        close_button = self.page.locator(close_selector).first
                        if await close_button.is_visible(timeout=1000):
                            await close_button.click()
                            logger.info(
                                f"ãƒ¢ãƒ¼ãƒ€ãƒ«/ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ã‚’é–‰ã˜ã¾ã—ãŸ: {close_selector}"
                            )
                            await self.page.wait_for_timeout(1000)
                            break
                except Exception as modal_error:
                    # It's ok if no modal is found
                    logger.debug(f"ãƒ¢ãƒ¼ãƒ€ãƒ«ãƒã‚§ãƒƒã‚¯: {modal_error}")

                # Press Escape key to dismiss any potential overlays
                try:
                    await self.page.keyboard.press("Escape")
                    await self.page.wait_for_timeout(500)
                except Exception as escape_error:
                    logger.debug(f"Escapeã‚­ãƒ¼æŠ¼ä¸‹ã‚¨ãƒ©ãƒ¼: {escape_error}")

                # Debug: Log all available link texts with comprehensive info
                try:
                    all_links_locator = self.page.locator("a")
                    link_count = await all_links_locator.count()
                    logger.info(f"ãƒšãƒ¼ã‚¸ä¸Šã®ãƒªãƒ³ã‚¯ç·æ•°: {link_count}")

                    # Get all text contents including those with the data type
                    all_links = await all_links_locator.all_text_contents()
                    links_with_data_type = [
                        link for link in all_links if display_name in link
                    ]
                    logger.info(
                        f"è¡¨ç¤ºå '{display_name}' ã‚’å«ã‚€ãƒªãƒ³ã‚¯: {links_with_data_type if links_with_data_type else 'è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“'}"
                    )

                    # Log links containing "A/C" or "åˆ¶å¾¡" or "Power"
                    relevant_links = [
                        link
                        for link in all_links
                        if any(
                            keyword in link
                            for keyword in ["A/C", "åˆ¶å¾¡", "Power", "Meter", "control"]
                        )
                    ]
                    logger.info(f"é–¢é€£ãƒªãƒ³ã‚¯: {relevant_links[:20]}")
                except Exception as debug_error:
                    logger.warning(f"ãƒªãƒ³ã‚¯ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°å–å¾—å¤±æ•—: {debug_error}")

                # Try multiple selector strategies for the button
                data_button = None

                # Determine href pattern based on data type (use original data_type for href pattern)
                href_pattern = None
                if data_type == "A/C Power Meter":
                    href_pattern = "/csv_logs/ac/power_meter/"
                elif data_type == "A/Cåˆ¶å¾¡" or display_name == "A/C Control":
                    href_pattern = "/csv_logs/ac/control/"

                selectors_to_try = []

                # Strategy 1: By href pattern (most reliable)
                if href_pattern:
                    selectors_to_try.append(
                        (
                            "href pattern",
                            self.page.locator(f"a[href*='{href_pattern}']").first,
                        )
                    )

                # Strategy 2: Exact text match using display_name
                selectors_to_try.append(
                    (
                        "exact text",
                        self.page.locator("a").filter(has_text=display_name).first,
                    )
                )

                # Strategy 3: Contains text (more flexible) using display_name
                selectors_to_try.append(
                    (
                        "contains text",
                        self.page.locator(f"a:has-text('{display_name}')").first,
                    )
                )

                # Strategy 4: Case-insensitive text match using display_name
                selectors_to_try.append(
                    (
                        "case-insensitive",
                        self.page.locator(f"a:text-is('{display_name}')").first,
                    )
                )

                # Strategy 5: Look for any link with display name words
                if " " in display_name:
                    words = display_name.split()
                    for word in words:
                        if len(word) > 2:  # Skip very short words
                            selectors_to_try.append(
                                (
                                    f"word: {word}",
                                    self.page.locator("a").filter(has_text=word).first,
                                )
                            )

                for selector_index, (strategy_name, selector) in enumerate(
                    selectors_to_try
                ):
                    try:
                        logger.info(
                            f"ã‚»ãƒ¬ã‚¯ã‚¿ãƒ¼æˆ¦ç•¥ {selector_index + 1} ({strategy_name}) ã‚’è©¦è¡Œä¸­: {data_type}"
                        )
                        await selector.wait_for(state="visible", timeout=10000)

                        # Verify this is actually the right button by checking text or href
                        button_text = await selector.text_content()
                        button_href = await selector.get_attribute("href")
                        logger.info(
                            f"å€™è£œãƒœã‚¿ãƒ³ç™ºè¦‹ - ãƒ†ã‚­ã‚¹ãƒˆ: '{button_text}', href: {button_href}"
                        )

                        # Validate it's the correct button
                        is_correct = False
                        if display_name in button_text:
                            is_correct = True
                        elif data_type in button_text:
                            is_correct = True
                        elif (
                            href_pattern and button_href and href_pattern in button_href
                        ):
                            is_correct = True

                        if is_correct:
                            data_button = selector
                            logger.info(
                                f"âœ“ æ­£ã—ã„ãƒœã‚¿ãƒ³ç™ºè¦‹ï¼ˆæˆ¦ç•¥{selector_index + 1}: {strategy_name}ï¼‰"
                            )
                            break
                        else:
                            logger.warning(f"å€™è£œã¯æ­£ã—ã„ãƒœã‚¿ãƒ³ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ")

                    except Exception as selector_error:
                        logger.debug(
                            f"ã‚»ãƒ¬ã‚¯ã‚¿ãƒ¼æˆ¦ç•¥ {selector_index + 1} ({strategy_name}) å¤±æ•—: {selector_error}"
                        )
                        continue

                if data_button is None:
                    raise Exception(
                        f"ã™ã¹ã¦ã®ã‚»ãƒ¬ã‚¯ã‚¿ãƒ¼æˆ¦ç•¥ã§ãƒœã‚¿ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ: {data_type}"
                    )

                # Wait for button to be attached to DOM
                logger.info(f"ãƒœã‚¿ãƒ³ã®DOMæ¥ç¶šã‚’ç¢ºèªä¸­: {data_type}")
                await data_button.wait_for(state="attached", timeout=30000)

                # Scroll button into view to ensure it's interactable in headless mode
                logger.info(f"ãƒœã‚¿ãƒ³ã‚’ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«è¡¨ç¤º: {data_type}")
                await data_button.scroll_into_view_if_needed()
                await self.page.wait_for_timeout(2000)

                # Verify button is enabled
                is_enabled = await data_button.is_enabled()
                if not is_enabled:
                    logger.warning(f"ãƒœã‚¿ãƒ³ãŒç„¡åŠ¹ã§ã™ã€å¾…æ©Ÿä¸­: {data_type}")
                    await self.page.wait_for_timeout(5000)

                # Get href for logging
                try:
                    href = await data_button.get_attribute("href", timeout=10000)
                    logger.info(f"ãƒœã‚¿ãƒ³ã®href: {href}")
                except Exception as href_error:
                    logger.warning(f"hrefå–å¾—å¤±æ•—ï¼ˆç¶šè¡Œã—ã¾ã™ï¼‰: {href_error}")

                # Perform download with extended timeout
                logger.info(f"ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¯ãƒªãƒƒã‚¯å®Ÿè¡Œ: {data_type}")
                async with self.page.expect_download(timeout=60000) as download_info:
                    await data_button.click(timeout=30000, force=True)

                download = await download_info.value
                filename = download.suggested_filename
                download_path = self.base_dir / "downloads" / filename
                await download.save_as(str(download_path))
                logger.info(f"ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†: {download_path}")

                # Track downloaded file with its data type
                self.downloaded_files.append(
                    {
                        "filename": filename,
                        "data_type": data_type,
                        "local_path": str(download_path),
                    }
                )

                # Wait for page to stabilize after download
                await self.page.wait_for_load_state("networkidle", timeout=30000)
                logger.info(f"ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¾Œã®å®‰å®šåŒ–å®Œäº†: {data_type}")

                return True

            except Exception as error:
                logger.error(
                    f"ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼ (è©¦è¡Œ {attempt + 1}/{max_retries}): {error}"
                )

                if attempt < max_retries - 1:
                    # Take screenshot for debugging
                    try:
                        screenshot_path = (
                            self.base_dir / "logs" / f"error_{data_type}_{attempt}.png"
                        )
                        await self.page.screenshot(path=str(screenshot_path))
                        logger.info(
                            f"ãƒ‡ãƒãƒƒã‚°ç”¨ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆä¿å­˜: {screenshot_path}"
                        )
                    except Exception as screenshot_error:
                        logger.warning(
                            f"ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆä¿å­˜å¤±æ•—: {screenshot_error}"
                        )

                    # Don't reload page - just wait longer as AC selections would be lost
                    logger.info(f"å¾…æ©Ÿå¾Œã«å†è©¦è¡Œã—ã¾ã™ï¼ˆãƒšãƒ¼ã‚¸ãƒªãƒ­ãƒ¼ãƒ‰ãªã—ï¼‰...")
                    await self.page.wait_for_timeout(5000)
                else:
                    logger.error(f"æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°ã«é”ã—ã¾ã—ãŸ: {data_type}")
                    return False

        return False

    def _get_gcs_path_for_data_type(self, data_type: str) -> str:
        """ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸGCSãƒ‘ã‚¹ã‚’å–å¾—"""
        if data_type == "A/C Power Meter":
            return GCPEnv.CLEA_AC_POWER_METER_PATH
        elif data_type == "A/Cåˆ¶å¾¡":
            return GCPEnv.CLEA_AC_CONTROL_PATH
        else:
            logger.warning(f"æœªçŸ¥ã®ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—: {data_type}, ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ã‚¹ã‚’ä½¿ç”¨")
            return GCPEnv.INPUT_DATA_FOLDER

    def _transform_dataframe_for_bigquery(
        self, data_frame: pd.DataFrame, data_type: str
    ) -> pd.DataFrame:
        """ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°çµæœã®DataFrameã‚’BigQueryã‚¹ã‚­ãƒ¼ãƒã«åˆã‚ã›ã¦å¤‰æ›"""

        if data_type == "A/Cåˆ¶å¾¡":
            rename_mapping = {
                "A/C Name": "AC_Name",
                "Datetime": "Datetime",
                "Outdoor Temp.": "Outdoor_Temp",
                "Indoor Temp.": "Indoor_Temp",
                "A/C Set Temperature": "AC_Set_Temperature",
                "A/C ON/OFF": "AC_ON_OFF",
                "A/C Mode": "AC_Mode",
                "A/C Fan Speed": "AC_Fan_Speed",
                "Naive Energy Level": "Naive_Energy_Level",
                "Airux Energy Level": "Airux_Energy_Level",
                "Outdoor Room Temp.": "Outdoor_Room_Temp",
                "Outdoor Set Temp.": "Outdoor_Set_Temp",
                "Room Set Temp.": "Room_Set_Temp",  # âœ” FIX
            }

            data_frame = data_frame.rename(columns=rename_mapping)

            target_columns = [
                "AC_Name",
                "Datetime",
                "Outdoor_Temp",
                "Indoor_Temp",
                "AC_Set_Temperature",
                "AC_ON_OFF",
                "AC_Mode",
                "AC_Fan_Speed",
                "Naive_Energy_Level",
                "Airux_Energy_Level",
                "Outdoor_Room_Temp",
                "Outdoor_Set_Temp",
                "Room_Set_Temp",  # âœ” FIX
            ]

        elif data_type == "A/C Power Meter":
            rename_mapping = {
                "Mesh ID": "Mesh_ID",
                "PM Addr ID": "PM_Addr_ID",
                "Datetime": "Datetime",
                "Phase A": "Phase_A",
                "Phase B": "Phase_B",
                "Phase C": "Phase_C",
            }

            data_frame = data_frame.rename(columns=rename_mapping)

            target_columns = [
                "Mesh_ID",
                "PM_Addr_ID",
                "Datetime",
                "Phase_A",
                "Phase_B",
                "Phase_C",
            ]

        else:
            return data_frame

        # Keep only expected columns
        existing_columns = [c for c in target_columns if c in data_frame.columns]
        data_frame = data_frame[existing_columns]

        # Ensure timestamp type
        if "Datetime" in data_frame.columns:
            data_frame["Datetime"] = pd.to_datetime(
                data_frame["Datetime"], errors="coerce", utc=True
            )

        return data_frame

    async def organize_downloaded_files(self, store_name, start_date, end_date):
        """ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã®æ•´ç†ï¼ˆã‚¹ãƒˆã‚¢åˆ¥ãƒ•ã‚©ãƒ«ãƒ€åˆ†ã‘ï¼‰ã€GCSã¸ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã€BigQueryã¸ã®æ›¸ãè¾¼ã¿"""
        try:
            logger.info("ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã®æ•´ç†é–‹å§‹")

            # ã‚¹ãƒˆã‚¢åˆ¥ãƒ•ã‚©ãƒ«ãƒ€ä½œæˆï¼ˆæœˆåˆ¥åˆ†ã‘ãªã—ï¼‰
            store_folder = self.base_dir / "alrux8_data" / store_name
            os.makedirs(str(store_folder), exist_ok=True)

            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ«ãƒ€å†…ã®å…¨CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç§»å‹•
            downloads_dir = self.base_dir / "downloads"
            if downloads_dir.exists():
                csv_files = [
                    f for f in os.listdir(str(downloads_dir)) if f.endswith(".csv")
                ]

                # Track files by data type for GCS upload
                files_by_data_type = {}
                for file_info in self.downloaded_files:
                    data_type = file_info["data_type"]
                    filename = file_info["filename"]
                    if filename in csv_files:
                        if data_type not in files_by_data_type:
                            files_by_data_type[data_type] = []
                        files_by_data_type[data_type].append(file_info)

                # Move files and upload to GCS
                for csv_file in csv_files:
                    source_path = downloads_dir / csv_file
                    dest_path = store_folder / csv_file

                    # Find the data type for this file
                    file_data_type = None
                    for data_type, file_list in files_by_data_type.items():
                        if any(f["filename"] == csv_file for f in file_list):
                            file_data_type = data_type
                            break

                    # Move file locally
                    shutil.move(str(source_path), str(dest_path))
                    logger.info(f"ãƒ•ã‚¡ã‚¤ãƒ«ç§»å‹•å®Œäº†: {dest_path}")

                    # Upload to GCS
                    if file_data_type:
                        gcs_path = self._get_gcs_path_for_data_type(file_data_type)
                        gcs_file_path = f"{gcs_path}{csv_file}"

                        try:
                            df = pd.read_csv(dest_path, low_memory=False)
                            # GCS upload
                            self.gcs_client.write_csv(df, gcs_file_path)
                            logger.info(f"GCSã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†: {gcs_file_path}")

                            # BigQuery ingest (append to raw tables)
                            try:
                                transformed_df = self._transform_dataframe_for_bigquery(
                                    df, file_data_type
                                )
                                if not transformed_df.empty:
                                    if file_data_type == "A/Cåˆ¶å¾¡":
                                        table_name = self.bq_table_ac_control_raw
                                    elif file_data_type == "A/C Power Meter":
                                        table_name = self.bq_table_ac_power_meter_raw
                                    else:
                                        table_name = None

                                    if table_name is not None:
                                        self.bq_client.write_dataframe(
                                            transformed_df,
                                            table_name=table_name,
                                            dataset_id=self.bq_dataset_id,
                                            if_exists="append",
                                        )
                                        logger.info(
                                            f"BigQueryæ›¸ãè¾¼ã¿å®Œäº†: {self.bq_dataset_id}.{table_name} "
                                            f"({len(transformed_df)} rows)"
                                        )
                                    else:
                                        logger.warning(
                                            f"BigQueryãƒ†ãƒ¼ãƒ–ãƒ«ãŒæœªå®šç¾©ã®ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—: {file_data_type}"
                                        )
                                else:
                                    logger.warning(
                                        f"BigQueryã«æ›¸ãè¾¼ã‚€è¡ŒãŒã‚ã‚Šã¾ã›ã‚“: {csv_file}"
                                    )
                            except Exception as bq_error:
                                logger.error(
                                    f"BigQueryæ›¸ãè¾¼ã¿ã‚¨ãƒ©ãƒ¼ ({csv_file}): {bq_error}"
                                )
                        except Exception as upload_error:
                            logger.error(
                                f"GCSã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼ ({csv_file}): {upload_error}"
                            )
                    else:
                        logger.warning(f"ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {csv_file}")

                # Delete downloads folder after all files are processed
                try:
                    if downloads_dir.exists():
                        shutil.rmtree(str(downloads_dir))
                        logger.info("downloadsãƒ•ã‚©ãƒ«ãƒ€ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
                except Exception as cleanup_error:
                    logger.warning(f"downloadsãƒ•ã‚©ãƒ«ãƒ€ã®å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {cleanup_error}")

                # Delete alrux8_data folder after all files are uploaded to GCS
                try:
                    alrux8_data_dir = self.base_dir / "alrux8_data"
                    if alrux8_data_dir.exists():
                        shutil.rmtree(str(alrux8_data_dir))
                        logger.info("alrux8_dataãƒ•ã‚©ãƒ«ãƒ€ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
                except Exception as cleanup_error:
                    logger.warning(f"alrux8_dataãƒ•ã‚©ãƒ«ãƒ€ã®å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {cleanup_error}")

            return True

        except Exception as e:
            logger.error(f"ãƒ•ã‚¡ã‚¤ãƒ«æ•´ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    def log_download_summary(self):
        """ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰çµæœã®è¦ç´„ãƒ­ã‚°"""
        logger.info("=" * 50)
        logger.info("ğŸ“Š ãƒ‡ãƒ¼ã‚¿å–å¾—çµæœè¦ç´„")
        logger.info("=" * 50)

        total_floors = len(self.download_summary)
        total_files = sum(len(files) for files in self.download_summary.values())

        logger.info(f"å‡¦ç†ãƒ•ãƒ­ã‚¢æ•°: {total_floors}")
        logger.info(f"å–å¾—ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {total_files}")
        logger.info("")

        for floor, files in self.download_summary.items():
            logger.info(f"ğŸ¢ {floor}: {len(files)}ãƒ•ã‚¡ã‚¤ãƒ«")
            for file in files:
                logger.info(f"  ğŸ“„ {file}")

        logger.info("=" * 50)

    async def run_scraping(
        self, username, password, store_name, start_date, end_date, data_types=None
    ):
        """ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Ÿè¡Œ"""
        try:
            logger.info(f"ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é–‹å§‹: {store_name}")

            if data_types is None:
                data_types = ["A/C Power Meter", "A/Cåˆ¶å¾¡"]

            # ãƒ–ãƒ©ã‚¦ã‚¶ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
            if not await self.setup_browser():
                return False

            # ãƒ­ã‚°ã‚¤ãƒ³
            if not await self.login(username, password):
                return False

            # Logsãƒšãƒ¼ã‚¸ã«ç§»å‹•
            if not await self.navigate_to_logs():
                return False

            # æ—¥ä»˜ç¯„å›²é¸æŠ
            if not await self.select_date_range(start_date, end_date):
                return False

            # ãƒ•ãƒ­ã‚¢ãƒ»A/Cãƒã‚¹ã‚¿å–å¾—
            master = await self.get_floor_ac_master()
            if not master:
                logger.error("ãƒ•ãƒ­ã‚¢ãƒ»A/Cãƒã‚¹ã‚¿æƒ…å ±å–å¾—å¤±æ•—")
                return False

            # ãƒ•ãƒ­ã‚¢ã‚’é€†é †ã§å‡¦ç†
            floors_reversed = list(reversed(list(master.keys())))
            logger.info(f"ãƒ•ãƒ­ã‚¢å‡¦ç†é †åºï¼ˆé€†é †ï¼‰: {floors_reversed}")

            for floor in floors_reversed:
                logger.info(f"ãƒ•ãƒ­ã‚¢å‡¦ç†é–‹å§‹: {floor}")
                floor_files = []
                try:
                    # ãƒ•ãƒ­ã‚¢é¸æŠ
                    if not await self.select_floor(floor):
                        logger.warning(f"ãƒ•ãƒ­ã‚¢ {floor} ã®é¸æŠã«å¤±æ•—ã€ã‚¹ã‚­ãƒƒãƒ—")
                        continue

                    # ãƒã‚¹ã‚¿ã‹ã‚‰A/Cæ©Ÿå™¨ãƒªã‚¹ãƒˆå–å¾—
                    ac_list = master[floor]
                    if not ac_list:
                        logger.error(f"ãƒ•ãƒ­ã‚¢ {floor} ã«A/Cæ©Ÿå™¨ãŒã‚ã‚Šã¾ã›ã‚“")
                        continue

                    print(f"A/Cæ©Ÿå™¨ãƒªã‚¹ãƒˆ: {ac_list}")
                    # æœ€å¤§5å°ã€æœ€ä½3å°
                    if len(ac_list) < 3:
                        ac_to_select = ac_list
                    else:
                        ac_to_select = ac_list[: min(len(ac_list), 5)]
                    selected_count = await self.select_ac_units_by_names(ac_to_select)
                    if selected_count < 3:
                        logger.warning(
                            f"ãƒ•ãƒ­ã‚¢ {floor} ã§A/Cæ©Ÿå™¨ãŒä¸è¶³ã—ã¦ã„ã¾ã™ ({selected_count}å°)"
                        )
                        continue

                    # ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—ã”ã¨ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                    for download_index, data_type in enumerate(data_types):
                        try:
                            success = await self.download_data_type(data_type)
                            if success:
                                floor_files.append(data_type)
                            else:
                                logger.warning(
                                    f"ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ— {data_type} ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ"
                                )
                            # Pause between downloads - longer for subsequent downloads
                            if download_index < len(data_types) - 1:
                                wait_time = 3000  # 3 seconds between downloads
                                logger.info(
                                    f"æ¬¡ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¾ã§ {wait_time}ms å¾…æ©Ÿä¸­..."
                                )
                                await self.page.wait_for_timeout(wait_time)
                        except Exception as error:
                            logger.error(
                                f"ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ— {data_type} ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {error}"
                            )
                            continue

                    # ãƒ•ãƒ­ã‚¢å‡¦ç†çµæœã‚’è¨˜éŒ²
                    self.download_summary[floor] = floor_files
                    logger.info(
                        f"ãƒ•ãƒ­ã‚¢ {floor} å‡¦ç†å®Œäº†: {len(floor_files)}ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—"
                    )

                except Exception as e:
                    logger.error(f"ãƒ•ãƒ­ã‚¢ {floor} å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                    # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã‚‚æ¬¡ã®ãƒ•ãƒ­ã‚¢ã«é€²ã‚€
                    continue

                await self.page.wait_for_timeout(1000)  # ãƒ•ãƒ­ã‚¢é–“ã®å¾…æ©Ÿæ™‚é–“ã‚’èª¿æ•´

            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã®æ•´ç†ã¨GCSã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
            await self.organize_downloaded_files(store_name, start_date, end_date)

            # Clear downloaded files tracking for next run
            self.downloaded_files = []

            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰çµæœã®è¦ç´„ãƒ­ã‚°
            self.log_download_summary()

            logger.info("ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Œäº†")
            return True

        except Exception as e:
            logger.error(f"ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    async def close(self):
        """ãƒ–ãƒ©ã‚¦ã‚¶ã‚’é–‰ã˜ã‚‹"""
        try:
            if self.browser:
                await self.browser.close()
            if self.playwright:
                await self.playwright.stop()
            logger.info("ãƒ–ãƒ©ã‚¦ã‚¶ã‚’é–‰ã˜ã¾ã—ãŸ")
        except Exception as e:
            logger.error(f"ãƒ–ãƒ©ã‚¦ã‚¶ã‚¯ãƒ­ãƒ¼ã‚ºã‚¨ãƒ©ãƒ¼: {e}")
