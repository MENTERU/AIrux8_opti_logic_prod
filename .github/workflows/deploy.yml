name: Deploy to GCP Cloud Run/Functions/Jobs

on:
  push:
    branches:
      - main
    paths:
      - "jobs/**"
      - "services/**"
      - "functions/**"

jobs:
  deploy:
    runs-on: ubuntu-latest
    environment: ${{ github.ref_name }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v3
        with:
          fetch-depth: 0 # Fetch full history for accurate git diff

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v1
        with:
          credentials_json: ${{ secrets.GHA_GCP_AIRUX8_DEPLOYER_SA }}

      - name: Setup gcloud CLI
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ vars.PROJECT_ID }}
          install_components: "alpha, beta"
          skip_install: false

      - name: Configure Docker for Artifact Registry
        run: |
          gcloud auth configure-docker ${{ vars.REGION }}-docker.pkg.dev


      # ðŸ”¹ Detect Changed Functions
      - name: Detect Changed Functions
        id: check_functions
        run: |
          if git rev-parse --verify HEAD^ >/dev/null 2>&1; then
            CHANGED_FUNCTIONS=$(git diff --name-only HEAD^ HEAD -- functions/ | awk -F'/' '{print $2}' | sort -u | paste -sd " " -)
          else
            CHANGED_FUNCTIONS=$(find functions -mindepth 1 -maxdepth 1 -type d -exec basename {} \; | paste -sd " " -)
          fi
          echo "Changed Functions: $CHANGED_FUNCTIONS"
          echo "CHANGED_FUNCTIONS=$CHANGED_FUNCTIONS" >> $GITHUB_ENV


      # ðŸ”¹ Detect Changed Jobs
      - name: Detect Changed Jobs
        id: check_jobs
        run: |
          if git rev-parse --verify HEAD^ >/dev/null 2>&1; then
            CHANGED_JOBS=$(git diff --name-only HEAD^ HEAD -- jobs/ | awk -F'/' '{print $2}' | sort -u | paste -sd " " -)
          else
            CHANGED_JOBS=$(find jobs -mindepth 1 -maxdepth 1 -type d -exec basename {} \; | paste -sd " " -)
          fi

          echo "Changed Jobs: $CHANGED_JOBS"
          echo "CHANGED_JOBS=$CHANGED_JOBS" >> $GITHUB_ENV


      # ðŸ”¹ Deploy Changed Jobs
      - name: Deploy Changed Jobs
        if: env.CHANGED_JOBS != ''
        run: |
          for dir in $CHANGED_JOBS; do
            dir_lower=$(echo "$dir" | tr '[:upper:]' '[:lower:]')
            
            # Skip if directory doesn't exist (renamed/deleted jobs)
            if [ ! -d "./jobs/$dir" ]; then
              echo "Skipping $dir - directory does not exist (likely renamed or deleted)"
              continue
            fi

            JOB_NAME=job-${dir_lower}-${{ vars.DEV_ENV }}
            
            IMAGE_NAME=${{ vars.REGION }}-docker.pkg.dev/${{ vars.PROJECT_ID }}/${{ vars.OPTIMIZE_ARTIFACT_REPO }}/job-$dir_lower:${{ vars.DEV_ENV }}
            echo "Building and deploying $JOB_NAME..."

            # Build and push Docker image from the job directory
            cd jobs/$dir
            docker buildx build --platform linux/amd64 -t $IMAGE_NAME . --push
            cd ../..
            echo "IMAGE_NAME=$IMAGE_NAME" >> $GITHUB_ENV

            # Deploy to Cloud Run Job
            if [ "$dir_lower" = "clea-data-scraping" ]; then
              gcloud run jobs deploy $JOB_NAME \
                --region=${{ vars.REGION }} \
                --image="$IMAGE_NAME" \
                --service-account=${{ vars.JOB_CLEA_DATA_SCRAPING_SA }} \
                --memory=2Gi \
                --cpu=1 \
                --task-timeout=900s \
                --max-retries=1 \
                --set-env-vars=PROJECT_ID=${{ vars.PROJECT_ID }},BUCKET_NAME=${{ vars.BUCKET_NAME }}

            elif [ "$dir_lower" = "trass-data-loader" ]; then
              # TODO: Add trass-data-loader deployment configuration
              echo "trass-data-loader deployment not yet configured"
            fi
          done


      # ðŸ”¹ Detect Changed Services
      - name: Detect Changed Services
        id: check_services
        run: |
          if git rev-parse --verify HEAD^ >/dev/null 2>&1; then
            CHANGED_SERVICES=$(git diff --name-only HEAD^ HEAD -- services/ | awk -F'/' '{print $2}' | sort -u | paste -sd " " -)
          else
            CHANGED_SERVICES=$(find services -mindepth 1 -maxdepth 1 -type d -exec basename {} \; | paste -sd " " -)
          fi

          echo "Changed Services: $CHANGED_SERVICES"
          echo "CHANGED_SERVICES=$CHANGED_SERVICES" >> $GITHUB_ENV

      # ðŸ”¹ Deploy Changed Services
      - name: Deploy Changed Services
        if: env.CHANGED_SERVICES != ''
        run: |
          for dir in $CHANGED_SERVICES; do
            dir_lower=$(echo "$dir" | tr '[:upper:]' '[:lower:]')
            
            # Skip if directory doesn't exist (renamed/deleted services)
            if [ ! -d "./services/$dir" ]; then
              echo "Skipping $dir - directory does not exist (likely renamed or deleted)"
              continue
            fi

            SVC_NAME=svc-${dir_lower}-${{ vars.DEV_ENV }}
            
            IMAGE_NAME=${{ vars.REGION }}-docker.pkg.dev/${{ vars.PROJECT_ID }}/${{ vars.OPTIMIZE_ARTIFACT_REPO }}/svc-$dir_lower:${{ vars.DEV_ENV }}
            echo "Building and deploying $SVC_NAME..."

            # Build and push Docker image from the service directory
            cd services/$dir
            docker buildx build --platform linux/amd64 -t $IMAGE_NAME . --push
            cd ../..
            echo "IMAGE_NAME=$IMAGE_NAME" >> $GITHUB_ENV

            # Deploy to Cloud Run Service
            if [ "$dir_lower" = "airux8-optimize" ]; then
              gcloud run deploy $SVC_NAME \
                --region=${{ vars.REGION }} \
                --image="$IMAGE_NAME" \
                --service-account=${{ vars.SVC_AIRUX8_OPTIMIZE_SA }} \
                --memory=2Gi \
                --cpu=1 \
                --timeout=900s \
                --max-instances=1 \
                --set-env-vars=STORAGE_BACKEND=gcs,PROJECT_ID=${{ vars.PROJECT_ID }},BUCKET_NAME=${{ vars.BUCKET_NAME }},CLEA_OUT_GDRIVE_FOLDER_ID=${{ vars.CLEA_OUT_GDRIVE_FOLDER_ID }} \
                --no-allow-unauthenticated \
                --ingress=internal
              # Get Cloud Run service URL
              SERVICE_URL=$(gcloud run services describe $SVC_NAME --region=${{ vars.REGION }} --format="value(status.url)")
              SCHEDULER_JOB_NAME=svc-${dir_lower}-${{ vars.DEV_ENV }}
              
              # Check if scheduler job exists and update or create
              if gcloud scheduler jobs describe $SCHEDULER_JOB_NAME --location=${{ vars.REGION }} 2>/dev/null; then
                echo "Updating existing scheduler job..."
                gcloud scheduler jobs update http $SCHEDULER_JOB_NAME \
                  --location="${{ vars.REGION }}" \
                  --schedule="0 1 * * *" \
                  --time-zone="Asia/Tokyo" \
                  --uri="$SERVICE_URL/execute_optimization_pipeline" \
                  --oidc-token-audience="$SERVICE_URL/execute_optimization_pipeline" \
                  --http-method="POST" \
                  --oidc-service-account-email="${{ vars.SVC_AIRUX8_OPTIMIZE_SA }}" \
                  --description="Run svc-airux8-optimize daily" || true
              else
                echo "Creating new scheduler job..."
                gcloud scheduler jobs create http $SCHEDULER_JOB_NAME \
                  --location="${{ vars.REGION }}" \
                  --schedule="0 1 * * *" \
                  --time-zone="Asia/Tokyo" \
                  --uri="$SERVICE_URL/execute_optimization_pipeline" \
                  --oidc-token-audience="$SERVICE_URL/execute_optimization_pipeline" \
                  --http-method="POST" \
                  --oidc-service-account-email="${{ vars.SVC_AIRUX8_OPTIMIZE_SA }}" \
                  --description="Run svc-airux8-optimize daily" || true
              fi
            fi
            
            
          done

       



      