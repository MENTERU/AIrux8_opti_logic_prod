name: Deploy to GCP Cloud Run/Functions/Jobs

on:
  push:
    branches:
      - main
    paths:
      - "jobs/**"
      - "services/**"
      - "functions/**"

jobs:
  deploy:
    runs-on: ubuntu-latest
    environment: ${{ github.ref_name }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v3
        with:
          fetch-depth: 0 # Fetch full history for accurate git diff

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v1
        with:
          credentials_json: ${{ secrets.GHA_GCP_AIRUX8_DEPLOYER_SA }}

      - name: Setup gcloud CLI
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ vars.PROJECT_ID }}
          install_components: "alpha, beta"
          skip_install: false

      - name: Configure Docker for Artifact Registry
        run: |
          gcloud auth configure-docker ${{ vars.REGION }}-docker.pkg.dev

      - name: Setup SSH Agent
        uses: webfactory/ssh-agent@v0.9.0
        with:
          ssh-private-key: ${{ secrets.MENTERU_TOOLS_DEPLOY_KEY }}


      # ðŸ”¹ Detect Changed Functions
      - name: Detect Changed Functions
        id: check_functions
        run: |
          if git rev-parse --verify HEAD^ >/dev/null 2>&1; then
            CHANGED_FUNCTIONS=$(git diff --name-only HEAD^ HEAD -- functions/ | awk -F'/' '{print $2}' | sort -u | paste -sd " " -)
          else
            CHANGED_FUNCTIONS=$(find functions -mindepth 1 -maxdepth 1 -type d -exec basename {} \; | paste -sd " " -)
          fi
          echo "Changed Functions: $CHANGED_FUNCTIONS"
          echo "CHANGED_FUNCTIONS=$CHANGED_FUNCTIONS" >> $GITHUB_ENV


      # ðŸ”¹ Detect Changed Jobs
      - name: Detect Changed Jobs
        id: check_jobs
        run: |
          if git rev-parse --verify HEAD^ >/dev/null 2>&1; then
            CHANGED_JOBS=$(git diff --name-only HEAD^ HEAD -- jobs/ | awk -F'/' '{print $2}' | sort -u | paste -sd " " -)
          else
            CHANGED_JOBS=$(find jobs -mindepth 1 -maxdepth 1 -type d -exec basename {} \; | paste -sd " " -)
          fi

          echo "Changed Jobs: $CHANGED_JOBS"
          echo "CHANGED_JOBS=$CHANGED_JOBS" >> $GITHUB_ENV


      # ðŸ”¹ Deploy Changed Jobs
      - name: Deploy Changed Jobs
        if: env.CHANGED_JOBS != ''
        run: |
          for dir in $CHANGED_JOBS; do
            dir_lower=$(echo "$dir" | tr '[:upper:]' '[:lower:]')
            
            # Skip if directory doesn't exist (renamed/deleted jobs)
            if [ ! -d "./jobs/$dir" ]; then
              echo "Skipping $dir - directory does not exist (likely renamed or deleted)"
              continue
            fi

            JOB_NAME=job-${dir_lower}-${{ vars.DEV_ENV }}
            
            IMAGE_NAME=${{ vars.REGION }}-docker.pkg.dev/${{ vars.PROJECT_ID }}/${{ vars.OPTIMIZE_ARTIFACT_REPO }}/job-$dir_lower:${{ vars.DEV_ENV }}
            echo "Building and deploying $JOB_NAME..."

            # Build and push Docker image          
            cd jobs/$dir
            DOCKER_BUILDKIT=1 docker buildx build \
              --platform linux/amd64 \
              --ssh default \
              -t $IMAGE_NAME . \
              --push
            
            cd ../..
            echo "IMAGE_NAME=$IMAGE_NAME" >> $GITHUB_ENV

            # Deploy to Cloud Run Job
            if [ "$dir_lower" = "clea-data-scraping" ]; then
              gcloud run jobs deploy $JOB_NAME \
                --region=${{ vars.REGION }} \
                --image="$IMAGE_NAME" \
                --service-account=${{ vars.JOB_CLEA_DATA_SCRAPING_SA }} \
                --memory=2Gi \
                --cpu=1 \
                --task-timeout=900s \
                --max-retries=1 \
                --set-env-vars=PROJECT_ID=${{ vars.PROJECT_ID }},BUCKET_NAME=${{ vars.BUCKET_NAME }}
            # Check if scheduler job exists and update or create
            if gcloud scheduler jobs describe job-clea-data-scraping-scheduler --location=${{ vars.REGION }} 2>/dev/null; then
                echo "Updating existing scheduler job..."
                gcloud scheduler jobs update http job-clea-data-scraping-scheduler \
                  --location="${{ vars.REGION }}" \
                  --schedule="0 0 * * *" \
                  --time-zone="Asia/Tokyo" \
                  --uri="https://${{ vars.REGION }}-run.googleapis.com/apis/run.googleapis.com/v1/namespaces/${{ vars.PROJECT_ID }}/jobs/$JOB_NAME:run" \
                  --http-method="POST" \
                  --oauth-service-account-email="${{ vars.JOB_ISETAN_DATA_SCRAPING_SA }}" \
                  --oauth-token-scope="https://www.googleapis.com/auth/cloud-platform" \
                  --description="Scheduler job that triggers $JOB_NAME everyday at 05:00 (JST)" \
                  --attempt-deadline=300s \
                  --min-backoff=60s \
                  --max-backoff=60s \
                  --max-retry-duration=300s
              else
                echo "Creating new scheduler job..."
                gcloud scheduler jobs create http job-clea-data-scraping-scheduler \
                  --location="${{ vars.REGION }}" \
                  --schedule="0 0 * * *" \
                  --time-zone="Asia/Tokyo" \
                  --uri="https://${{ vars.REGION }}-run.googleapis.com/apis/run.googleapis.com/v1/namespaces/${{ vars.PROJECT_ID }}/jobs/$JOB_NAME:run" \
                  --http-method="POST" \
                  --oauth-service-account-email="${{ vars.JOB_ISETAN_DATA_SCRAPING_SA }}" \
                  --oauth-token-scope="https://www.googleapis.com/auth/cloud-platform" \
                  --description="Scheduler job that triggers $JOB_NAME everyday at 05:00 (JST)" \
                  --attempt-deadline=300s \
                  --min-backoff=60s \
                  --max-backoff=60s \
                  --max-retry-duration=300s
              fi
            elif [ "$dir_lower" = "isetan-data-scraping" ]; then
              gcloud run jobs deploy $JOB_NAME \
                --region=${{ vars.REGION }} \
                --image="$IMAGE_NAME" \
                --service-account=${{ vars.JOB_ISETAN_DATA_SCRAPING_SA }} \
                --memory=2Gi \
                --cpu=1 \
                --task-timeout=900s \
                --max-retries=3 \
                --set-env-vars=PROJECT_ID=${{ vars.PROJECT_ID }},BUCKET_NAME=${{ vars.BUCKET_NAME }}
              # Check if scheduler job exists and update or create
              if gcloud scheduler jobs describe job-$dir_lower-scheduler --location=${{ vars.REGION }} 2>/dev/null; then
                echo "Updating existing scheduler job..."
                gcloud scheduler jobs update http job-$dir_lower-scheduler \
                  --location="${{ vars.REGION }}" \
                  --schedule="0 0 * * *" \
                  --time-zone="Asia/Tokyo" \
                  --uri="https://${{ vars.REGION }}-run.googleapis.com/apis/run.googleapis.com/v1/namespaces/${{ vars.PROJECT_ID }}/jobs/$JOB_NAME:run" \
                  --http-method="POST" \
                  --oauth-service-account-email="${{ vars.JOB_ISETAN_DATA_SCRAPING_SA }}" \
                  --oauth-token-scope="https://www.googleapis.com/auth/cloud-platform" \
                  --description="Scheduler job that triggers $JOB_NAME everyday at 05:00 (JST)" \
                  --attempt-deadline=300s \
                  --min-backoff=60s \
                  --max-backoff=60s \
                  --max-retry-duration=300s
              else
                echo "Creating new scheduler job..."
                gcloud scheduler jobs create http job-$dir_lower-scheduler \
                  --location="${{ vars.REGION }}" \
                  --schedule="0 0 * * *" \
                  --time-zone="Asia/Tokyo" \
                  --uri="https://${{ vars.REGION }}-run.googleapis.com/apis/run.googleapis.com/v1/namespaces/${{ vars.PROJECT_ID }}/jobs/$JOB_NAME:run" \
                  --http-method="POST" \
                  --oauth-service-account-email="${{ vars.JOB_ISETAN_DATA_SCRAPING_SA }}" \
                  --oauth-token-scope="https://www.googleapis.com/auth/cloud-platform" \
                  --description="Scheduler job that triggers $JOB_NAME everyday at 05:00 (JST)" \
                  --attempt-deadline=300s \
                  --min-backoff=60s \
                  --max-backoff=60s \
                  --max-retry-duration=300s
            fi
            elif [ "$dir_lower" = "trass-data-loader" ]; then
              gcloud run jobs deploy $JOB_NAME \
                --region=${{ vars.REGION }} \
                --image="$IMAGE_NAME" \
                --service-account=${{ vars.JOB_TRASS_DATA_LOADER_SA }} \
                --task-timeout=1200s \
                --max-retries=0 \
                --set-env-vars "PROJECT_ID=${{ vars.PROJECT_ID }}" \
                --set-env-vars "BUCKET_NAME=${{ vars.BUCKET_NAME }}" \
                --set-env-vars "START_DATE=" \
                --set-env-vars "END_DATE=" \
                --set-env-vars "FACILITY_ID=" \
                --set-env-vars "MASTER_DATA_PATH=${{ vars.DATA_LOADER_MASTER_DATA_PATH }}" \
                --set-env-vars "LOADED_DATA_PATH=${{ vars.DATA_LOADER_LOADED_DATA_PATH }}" 
              # Check if scheduler job exists
              if gcloud scheduler jobs describe job-$dir_lower-scheduler --location=${{ vars.REGION }} 2>/dev/null; then
                echo "Updating existing scheduler job..."
                gcloud scheduler jobs update http job-$dir_lower-scheduler \
                  --location="${{ vars.REGION }}" \
                  --schedule="0 5 * * *" \
                  --time-zone="Asia/Tokyo" \
                  --uri="https://${{ vars.REGION }}-run.googleapis.com/apis/run.googleapis.com/v1/namespaces/${{ vars.PROJECT_ID }}/jobs/$JOB_NAME:run" \
                  --http-method="POST" \
                  --oauth-service-account-email="${{ vars.JOB_TRASS_DATA_LOADER_SA }}" \
                  --oauth-token-scope="https://www.googleapis.com/auth/cloud-platform" \
                  --description="Scheduler job that triggers $JOB_NAME everyday at 05:00 (JST)" \
                  --attempt-deadline=300s \
                  --min-backoff=60s \
                  --max-backoff=60s \
                  --max-retry-duration=300s
              else
                echo "Creating new scheduler job..."
                gcloud scheduler jobs create http job-$dir_lower-scheduler \
                  --location="${{ vars.REGION }}" \
                  --schedule="0 5 * * *" \
                  --time-zone="Asia/Tokyo" \
                  --uri="https://${{ vars.REGION }}-run.googleapis.com/apis/run.googleapis.com/v1/namespaces/${{ vars.PROJECT_ID }}/jobs/$JOB_NAME:run" \
                  --http-method="POST" \
                  --oauth-service-account-email="${{ vars.JOB_TRASS_DATA_LOADER_SA }}" \
                  --oauth-token-scope="https://www.googleapis.com/auth/cloud-platform" \
                  --description="Scheduler job that triggers $JOB_NAME everyday at 05:00 (JST)" \
                  --attempt-deadline=300s \
                  --min-backoff=60s \
                  --max-backoff=60s \
                  --max-retry-duration=300s
              fi
            fi
          done


      # ðŸ”¹ Deploy Changed Cloud Functions
      - name: Deploy Changed Cloud Functions
        if: ${{ env.CHANGED_FUNCTIONS != '' }}
        run: |
          for dir in $CHANGED_FUNCTIONS; do
            dir_lower=$(echo "$dir" | tr '[:upper:]' '[:lower:]')
            
            # Skip if directory doesn't exist
            if [ ! -d "./functions/$dir" ]; then
              echo "Skipping $dir - directory does not exist"
              continue
            fi
            
            if [ "$dir_lower" = "func-check-clea-files" ]; then
              echo "Deploying Cloud Function: ${dir_lower}-${{ vars.DEV_ENV }}"
              gcloud functions deploy ${dir_lower}-${{ vars.DEV_ENV }} \
                --gen2 \
                --runtime=python311 \
                --region=asia-northeast1 \
                --source=./functions/$dir_lower \
                --entry-point=check_clea_files \
                --trigger-http \
                --allow-unauthenticated \
                --service-account=${{ vars.FUNC_CHECK_CLEA_FILES_SA }} \
                --set-env-vars BUCKET_NAME=${{ vars.BUCKET_NAME }} \
                --set-secrets SLACK_WEBHOOK_URL=SLACK_WEBHOOK_URL:latest
            fi
          done
          
          
      # ðŸ”¹ Detect Changed Services
      - name: Detect Changed Services
        id: check_services
        run: |
          if git rev-parse --verify HEAD^ >/dev/null 2>&1; then
            CHANGED_SERVICES=$(git diff --name-only HEAD^ HEAD -- services/ | awk -F'/' '{print $2}' | sort -u | paste -sd " " -)
          else
            CHANGED_SERVICES=$(find services -mindepth 1 -maxdepth 1 -type d -exec basename {} \; | paste -sd " " -)
          fi

          echo "Changed Services: $CHANGED_SERVICES"
          echo "CHANGED_SERVICES=$CHANGED_SERVICES" >> $GITHUB_ENV

      # ðŸ”¹ Deploy Changed Services
      - name: Deploy Changed Services
        if: env.CHANGED_SERVICES != ''
        run: |
          for dir in $CHANGED_SERVICES; do
            dir_lower=$(echo "$dir" | tr '[:upper:]' '[:lower:]')
            
            # Skip if directory doesn't exist (renamed/deleted services)
            if [ ! -d "./services/$dir" ]; then
              echo "Skipping $dir - directory does not exist (likely renamed or deleted)"
              continue
            fi

            SVC_NAME=svc-${dir_lower}-${{ vars.DEV_ENV }}
            
            IMAGE_NAME=${{ vars.REGION }}-docker.pkg.dev/${{ vars.PROJECT_ID }}/${{ vars.OPTIMIZE_ARTIFACT_REPO }}/svc-$dir_lower:${{ vars.DEV_ENV }}
            echo "Building and deploying $SVC_NAME..."

            # Build and push Docker image from the service directory
            cd services/$dir
            docker buildx build --platform linux/amd64 -t $IMAGE_NAME . --push
            cd ../..
            echo "IMAGE_NAME=$IMAGE_NAME" >> $GITHUB_ENV

            # Deploy to Cloud Run Service
            if [ "$dir_lower" = "airux8-optimize" ]; then
              gcloud run deploy $SVC_NAME \
                --region=${{ vars.REGION }} \
                --image="$IMAGE_NAME" \
                --service-account=${{ vars.SVC_AIRUX8_OPTIMIZE_SA }} \
                --memory=2Gi \
                --cpu=1 \
                --timeout=900s \
                --max-instances=1 \
                --set-env-vars=STORAGE_BACKEND=gcs,PROJECT_ID=${{ vars.PROJECT_ID }},BUCKET_NAME=${{ vars.BUCKET_NAME }},CLEA_OUT_GDRIVE_FOLDER_ID=${{ vars.CLEA_OUT_GDRIVE_FOLDER_ID }} \
                --no-allow-unauthenticated \
                --ingress=internal
              # Get Cloud Run service URL
              SERVICE_URL=$(gcloud run services describe $SVC_NAME --region=${{ vars.REGION }} --format="value(status.url)")
              SCHEDULER_JOB_NAME=svc-${dir_lower}-${{ vars.DEV_ENV }}
              
              # Check if scheduler job exists and update or create
              if gcloud scheduler jobs describe $SCHEDULER_JOB_NAME --location=${{ vars.REGION }} 2>/dev/null; then
                echo "Updating existing scheduler job..."
                gcloud scheduler jobs update http $SCHEDULER_JOB_NAME \
                  --location="${{ vars.REGION }}" \
                  --schedule="0 1 * * *" \
                  --time-zone="Asia/Tokyo" \
                  --uri="$SERVICE_URL/execute_optimization_pipeline" \
                  --oidc-token-audience="$SERVICE_URL/execute_optimization_pipeline" \
                  --http-method="POST" \
                  --oidc-service-account-email="${{ vars.SVC_AIRUX8_OPTIMIZE_SA }}" \
                  --description="Run svc-airux8-optimize daily" || true
              else
                echo "Creating new scheduler job..."
                gcloud scheduler jobs create http $SCHEDULER_JOB_NAME \
                  --location="${{ vars.REGION }}" \
                  --schedule="0 1 * * *" \
                  --time-zone="Asia/Tokyo" \
                  --uri="$SERVICE_URL/execute_optimization_pipeline" \
                  --oidc-token-audience="$SERVICE_URL/execute_optimization_pipeline" \
                  --http-method="POST" \
                  --oidc-service-account-email="${{ vars.SVC_AIRUX8_OPTIMIZE_SA }}" \
                  --description="Run svc-airux8-optimize daily" || true
              fi
            fi
            
            
          done

       



      